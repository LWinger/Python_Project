%matplotlib inline

#connect to mySQL & import necessary packages
import pymysql #Connector library for mysql
import matplotlib
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import urllib
import nltk

#Set up a connection with the server
conn = pymysql.connect(host='localhost', port=3307, user='root')
#And a cursor object that will serve as a virtual 'cursor'
curr = conn.cursor()

reviews = pd.read_sql('select * from NYC_sleep_eat.reviews;', conn)

#clean review date
a = reviews['review_date'].astype(str).str.split().str.get(0).str[2:]
reviews['review_date'] = str('20') + a
reviews['review_date'] = pd.to_datetime(reviews['review_date'])

lower = reviews['review'].astype(str).str.lower().values.tolist()

#drop 'new york'
rev_list = []
j = 0
b = 0
while (j < len(lower)):
    b = lower[j].replace('new york','')
    rev_list.append(b)
    j+=1


#get sentiment dictionary from Wislon et al. if you don't have it
#files=['negative.txt','positive.txt']
#path='http://www.unc.edu/~ncaren/haphazard/'
#for file_name in files:
#    urllib.request.urlretrieve(path+file_name,file_name)

pos_sent = open("positive.txt").read()
positive_words = pos_sent.split('\n')

neg_sent = open("negative.txt").read()
negative_words = neg_sent.split('\n')


#define get sentiment function
def get_sentiment(text):
    positive_counter = 0
    negative_counter = 0
    positive_counts=[]
    negative_counts=[]
    sentiment = []

    for word in text:
        if word in positive_words:
            positive_counter = positive_counter+1
    if len(text)> 0:
        positive_counts.append(positive_counter/len(text))
    else:
        positive_counts.append('')

    for word in words:
        if word in negative_words:
            negative_counter = negative_counter+1
    if len(text)> 0:
        negative_counts.append(negative_counter/len(text))
    else:
        negative_counts.append('')

    sentiment = [positive_counts,negative_counts]

    return sentiment

#new kernal
from nltk import sent_tokenize,word_tokenize
from nltk.corpus import wordnet as wn

#new kernal
#careful because the following loop runs for all 200,000+ reviews....
words_sentiments = []
adj_sentiments = []

for i in rev_list:
    adjectives = []
    words = nltk.Text(word_tokenize(str(i)))

    for eachword in words:
        ss = wn.synsets(eachword)
        if len(ss) > 0:
            pos = [xx.pos() for xx in ss]
            if 's' in pos:
                adjectives.append(eachword)
    
    x = get_sentiment(adjectives)
    adj_sentiments.append(x)
    
    y = get_sentiment(words)
    words_sentiments.append(y)

